{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc57631358ebf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:53:59.235512Z",
     "start_time": "2025-09-29T16:53:59.013409Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Callable, Any\n",
    "import imageio.v2 as imageio\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "import gymnasium as gym\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98184a8781a3a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:53:59.240080Z",
     "start_time": "2025-09-29T16:53:59.238144Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Emergent CA (discrete space, continuous time) — minimal notebook\n",
    "# Configure parameters & seed here, then run the following cells.\n",
    "# The model integrates with RK4 and plots a 1-D CA-style spacetime diagram\n",
    "# for a(t) and m(t): x-axis = space; y-axis (down) = time steps.\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# ---- Config (edit these) ----\n",
    "N   = 125        # number of cells (space)\n",
    "T   = 125          # number of integration steps (time depth)\n",
    "dt  = 0.05         # time step (continuous-time integrator)\n",
    "\n",
    "alpha_m = 0.1      # memory leak rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79566471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:53:59.291184Z",
     "start_time": "2025-09-29T16:53:59.282608Z"
    }
   },
   "outputs": [],
   "source": [
    "class CEM():\n",
    "    def __init__(self, N, T, dt, alpha_m, persist = False):\n",
    "\n",
    "        # Local polynomial coefficients (theta_*):\n",
    "        # dot a_i = theta1 + theta_c*c + theta_l*l + theta_r*r + theta_m*m\n",
    "        #           + theta_cl*c*l + theta_cr*c*r + theta_cm*c*m\n",
    "        self.theta = {'theta1': 1.4376621267715537, 'theta_c': -7.8766253635181105, 'theta_l': -2.722349618817911, 'theta_r': 2.0576759135197538, 'theta_m': -8.45005113559998, 'theta_cl': -0.12868716237756087, 'theta_cr': 0.30220266691459485, 'theta_cm': -0.1061964674000701}\n",
    "        self.N = N\n",
    "        self.T = T\n",
    "        self.dt = dt\n",
    "        self.alpha_m = alpha_m\n",
    "\n",
    "       # RNG seed for reproducible initial state\n",
    "        self.A, self.M = self.__init_state__()\n",
    "\n",
    "        spacing = N//5\n",
    "        self.input_locs = [0*spacing, 1*spacing, 3*spacing, 4*spacing]\n",
    "        self.output_locs = [2*spacing]\n",
    "\n",
    "        self.A_mask = np.ones_like(self.A)\n",
    "        if persist:\n",
    "            self.A_mask[:, self.input_locs] = 0\n",
    "\n",
    "    def __init_state__(self, state = None):\n",
    "        if state is None:\n",
    "            init_scale = 3e-1  # amplitude of random initialization\n",
    "            rng = np.random.default_rng(42)\n",
    "            a0 = init_scale * rng.standard_normal(self.N)\n",
    "            m0 = init_scale * rng.standard_normal(self.N)\n",
    "\n",
    "            A = np.empty((self.T+1, self.N), dtype=float)\n",
    "            M = np.empty((self.T+1, self.N), dtype=float)\n",
    "            A[0] = a0\n",
    "            M[0] = m0\n",
    "\n",
    "            return A,M\n",
    "        if state is not None:\n",
    "            self.A[0], self.M[0] = state\n",
    "\n",
    "\n",
    "    def norm_obs(self,x, dx, th, dth ):\n",
    "        # clip to reasonable limits\n",
    "        x  = np.clip(x,  -2.4,  2.4)   / 2.4\n",
    "        dx = np.clip(dx, -3.0,  3.0)   / 3.0\n",
    "        th = np.clip(th, -0.418, 0.418) / 0.418\n",
    "        dth= np.clip(dth,-4.0,  4.0)   / 4.0\n",
    "        return np.array([x, dx, th, dth], dtype=float)\n",
    "\n",
    "\n",
    "# %%\n",
    "# ---- Dynamics (periodic boundary; RK4 integrator) ----\n",
    "\n",
    "    def seed_inputs(self, x, dx , theta, dtheta):\n",
    "        self.A[0,self.input_locs] = self.norm_obs(x, dx, theta, dtheta)\n",
    "\n",
    "\n",
    "\n",
    "    def deriv(self,a, m):\n",
    "        \"\"\"Compute time-derivatives (dot a, dot m) given current (a, m).\"\"\"\n",
    "        l = np.roll(a, 1)   # a_{i-1}\n",
    "        r = np.roll(a, -1)  # a_{i+1}\n",
    "        c = a\n",
    "        t = self.theta\n",
    "        dot_a = (t[\"theta1\"]\n",
    "                 + t[\"theta_c\"]*c + t[\"theta_l\"]*l + t[\"theta_r\"]*r + t[\"theta_m\"]*m\n",
    "                 + t[\"theta_cl\"]*c*l + t[\"theta_cr\"]*c*r + t[\"theta_cm\"]*c*m) - 5*self.alpha_m*c\n",
    "        dot_m = self.alpha_m * (a - m)\n",
    "        return dot_a, dot_m\n",
    "\n",
    "    def rk4_step(self,a, m):\n",
    "        \"\"\"One RK4 step for the coupled ODEs.\"\"\"\n",
    "        k1_a, k1_m = self.deriv(a, m)\n",
    "        k2_a, k2_m = self.deriv(a + 0.5*self.dt*k1_a, m + 0.5*self.dt*k1_m)\n",
    "        k3_a, k3_m = self.deriv(a + 0.5*self.dt*k2_a, m + 0.5*self.dt*k2_m)\n",
    "        k4_a, k4_m = self.deriv(a + self.dt*k3_a,     m + self.dt*k3_m)\n",
    "        a_next = a + (self.dt/6.0)*(k1_a + 2*k2_a + 2*k3_a + k4_a)\n",
    "        m_next = m + (self.dt/6.0)*(k1_m + 2*k2_m + 2*k3_m + k4_m)\n",
    "        return a_next, m_next\n",
    "\n",
    "    def simulate(self, x, dx , theta, dtheta):\n",
    "        self.seed_inputs(x, dx, theta, dtheta)\n",
    "        for t in range(1, self.T+1):\n",
    "\n",
    "            a,m = self.A[t-1], self.M[t-1]\n",
    "            a, m = self.rk4_step(a, m)\n",
    "            self.A[t] = a * self.A_mask[t]\n",
    "            self.M[t] = m\n",
    "        return self.A[:, self.output_locs]\n",
    "\n",
    "class CEM1Layer:\n",
    "\n",
    "    def __init__(self, N, T, dt, alpha_m,\n",
    "                 theta=None, gamma=0.0, rng_seed=42, init_scale=1.0, persist=False):\n",
    "        self.N = int(N)\n",
    "        self.T = int(T)\n",
    "        self.dt = float(dt)\n",
    "        self.alpha_m = float(alpha_m)   # kept for interface compatibility\n",
    "        self.gamma = float(gamma)\n",
    "\n",
    "\n",
    "        spacing = N//5\n",
    "        self.input_locs = [0*spacing, 1*spacing, 3*spacing, 4*spacing]\n",
    "        self.output_locs = [2*spacing]\n",
    "\n",
    "\n",
    "\n",
    "        if theta is None:\n",
    "            self.theta = {\n",
    "                \"k0\": random.uniform(-0.10,  0.10),\n",
    "                \"k1\": random.uniform(-0.40,  0.40),\n",
    "                \"k2\": random.uniform(-0.60,  0.60),\n",
    "                \"k3\": random.uniform(-0.40,  0.40),\n",
    "                \"k4\": random.uniform(-0.30,  0.30),\n",
    "                \"k5\": random.uniform(-0.30,  0.30),\n",
    "                \"k6\": random.uniform(-0.15,  0.15),\n",
    "            }\n",
    "        else:\n",
    "            keys = [\"k0\",\"k1\",\"k2\",\"k3\",\"k4\",\"k5\",\"k6\"]\n",
    "            self.theta = {k: float(theta.get(k, 0.0)) for k in keys}\n",
    "\n",
    "        # Allocate state history buffers to mirror your class\n",
    "        self.A = np.empty((self.T + 1, self.N), dtype=float)\n",
    "        self.A_mask = np.ones_like(self.A)\n",
    "        if persist:\n",
    "            self.A_mask[:, self.input_locs] = 0\n",
    "\n",
    "\n",
    "        # Fitness bookkeeping (mirrors your attributes)\n",
    "        self.fitness = -1e3\n",
    "        self.fit_res = None\n",
    "\n",
    "        # Initialize state (A[0]) like your __init_state__\n",
    "        self.__init_state__(state=None, rng_seed=rng_seed, init_scale=init_scale)\n",
    "\n",
    "    # ---- Initialization (mirrors your signature/behavior) ----\n",
    "    def __init_state__(self, state=None, rng_seed=42, init_scale=1.0):\n",
    "        \"\"\"\n",
    "        If state is None: random normal initial A[0].\n",
    "        If state is a tuple/list (A0, M0) from old 2-layer code, we use only A0.\n",
    "        If state is a 1D array of shape (N,), we use it as A[0].\n",
    "        \"\"\"\n",
    "        if state is None:\n",
    "            rng = np.random.default_rng(rng_seed)\n",
    "            a0 = init_scale * rng.standard_normal(self.N)\n",
    "            self.A[0] = a0\n",
    "            return self.A\n",
    "\n",
    "        else:\n",
    "            a0 = np.asarray(state, dtype=float)\n",
    "\n",
    "        assert a0.shape == (self.N,), f\"Initial state must be shape (N,), got {a0.shape}\"\n",
    "        self.A[0] = a0\n",
    "        return self.A\n",
    "\n",
    "    def norm_obs(self,x, dx, th, dth ):\n",
    "        # clip to reasonable limits\n",
    "        x  = np.clip(x,  -2.4,  2.4)   / 2.4\n",
    "        dx = np.clip(dx, -3.0,  3.0)   / 3.0\n",
    "        th = np.clip(th, -0.418, 0.418) / 0.418\n",
    "        dth= np.clip(dth,-4.0,  4.0)   / 4.0\n",
    "        return np.array([x, dx, th, dth], dtype=float)\n",
    "\n",
    "    def seed_inputs(self, x, dx , theta, dtheta):\n",
    "        #self.A[0,self.input_locs] = self.norm_obs(x, dx, theta, dtheta)\n",
    "        self.A[0,self.input_locs] = x, dx, theta, dtheta\n",
    "\n",
    "    # ---- Dynamics (periodic boundary; RK4 integrator) ----\n",
    "    def deriv(self, a):\n",
    "        \"\"\"Compute ds/dt for the current state a (periodic neighborhood).\"\"\"\n",
    "        l = np.roll(a,  1)\n",
    "        r = np.roll(a, -1)\n",
    "        c = a\n",
    "        t = self.theta\n",
    "        dot = (t[\"k0\"]\n",
    "               + t[\"k1\"]*l + t[\"k2\"]*c + t[\"k3\"]*r\n",
    "               + t[\"k4\"]*(c*r) + t[\"k5\"]*(c*l)\n",
    "               + t[\"k6\"]*(l*c*r)\n",
    "               - self.gamma * c)\n",
    "        return dot\n",
    "\n",
    "    def rk4_step(self, a):\n",
    "        \"\"\"One RK4 step for ds/dt = f(a).\"\"\"\n",
    "        k1 = self.deriv(a)\n",
    "        k2 = self.deriv(a + 0.5*self.dt*k1)\n",
    "        k3 = self.deriv(a + 0.5*self.dt*k2)\n",
    "        k4 = self.deriv(a + self.dt*k3)\n",
    "        a_next = a + (self.dt/6.0)*(k1 + 2*k2 + 2*k3 + k4)\n",
    "        return a_next\n",
    "\n",
    "\n",
    "    def simulate(self,x,dx, theta, dtheta):\n",
    "        self.seed_inputs(x, dx, theta, dtheta)\n",
    "        \"\"\"Run T integration steps, filling self.A[1:].\"\"\"\n",
    "        for t in range(1, self.T + 1):\n",
    "            a_prev = self.A[t - 1]\n",
    "            a_next = self.rk4_step(a_prev)\n",
    "            self.A[t] = a_next\n",
    "        return self.A[:,self.output_locs]\n",
    "\n",
    "    # ---- Helpers to mirror ergonomics ----\n",
    "    def set_theta(self, **kwargs):\n",
    "        \"\"\"Update any subset of k0..k6 (e.g., set_theta(k2=0.1, k6=-0.05)).\"\"\"\n",
    "        for k, v in kwargs.items():\n",
    "            if k not in self.theta:\n",
    "                raise KeyError(f\"Unknown coefficient '{k}'. Valid keys: {list(self.theta.keys())}\")\n",
    "            self.theta[k] = float(v)\n",
    "\n",
    "    def get_theta(self):\n",
    "        return dict(self.theta)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0faf56b9e4905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:53:59.354620Z",
     "start_time": "2025-09-29T16:53:59.334336Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install gymnasium numpy imageio imageio-ffmpeg\n",
    "\n",
    "\n",
    "# ---- import your final CEM class here ----\n",
    "# from your_file import CEM\n",
    "# (Make sure CEM is top-level and pickleable for multiprocessing.)\n",
    "\n",
    "Theta = Dict[str, float]\n",
    "THETA_KEYS = [\n",
    "    \"k0\",\"k1\",\"k2\",\"k3\",\"k4\",\"k5\",\"k6\"\n",
    "]\n",
    "#THETA_KEYS = [\"theta1\",\"theta_c\",\"theta_l\",\"theta_r\",\"theta_m\",\"theta_cl\",\"theta_cr\",\"theta_cm\"]\n",
    "\n",
    "# ---------- EA helpers ----------\n",
    "def theta_to_vec(theta: Theta) -> np.ndarray:\n",
    "    return np.array([theta[k] for k in THETA_KEYS], dtype=float)\n",
    "\n",
    "def vec_to_theta(vec: np.ndarray) -> Theta:\n",
    "    return {k: float(v) for k, v in zip(THETA_KEYS, vec)}\n",
    "\n",
    "def clone_theta(theta: Theta) -> Theta:\n",
    "    return {k: float(v) for k, v in theta.items()}\n",
    "\n",
    "def random_theta(rng: np.random.Generator, low=-0.7, high=0.7) -> Theta:\n",
    "    return {k: float(v) for k, v in zip(THETA_KEYS, rng.uniform(low, high, len(THETA_KEYS)))}\n",
    "\n",
    "def uniform_crossover(a: Theta, b: Theta, rng: np.random.Generator, swap_p=0.5) -> Theta:\n",
    "    return {k: (a[k] if rng.random() > swap_p else b[k]) for k in THETA_KEYS}\n",
    "\n",
    "def mutate(theta: Theta, rng: np.random.Generator, pmut=0.25, sigma=0.12, clip=(-1.5,1.5)) -> Theta:\n",
    "    v = theta_to_vec(theta)\n",
    "    for i in range(v.size):\n",
    "        if rng.random() < pmut:\n",
    "            v[i] += rng.normal(0.0, sigma)\n",
    "    # gentle push to keep theta_cm a bit negative\n",
    "    \"\"\"i_cm = THETA_KEYS.index(\"theta_cm\")\n",
    "    if rng.random() < 0.1:\n",
    "        v[i_cm] = v[i_cm] - abs(rng.normal(0.0, sigma/2))\"\"\"\n",
    "    v = np.clip(v, *clip)\n",
    "    return vec_to_theta(v)\n",
    "\n",
    "def tournament_select(pop_fit: List[Tuple[Theta,float]], rng: np.random.Generator, k=3) -> Theta:\n",
    "    idxs = rng.choice(len(pop_fit), size=k, replace=False)\n",
    "    best = max(idxs, key=lambda i: pop_fit[i][1])\n",
    "    return clone_theta(pop_fit[best][0])\n",
    "\n",
    "# ---------- configs ----------\n",
    "@dataclass\n",
    "class CEMConfig:\n",
    "    N: int = 16\n",
    "    T: int = 32       # micro-steps per env step\n",
    "    dt: float = 0.02\n",
    "    alpha_m: float = 0.2\n",
    "\n",
    "@dataclass\n",
    "class EvalConfig:\n",
    "    env_id: str = \"CartPole-v1\"\n",
    "    max_steps: int = 500\n",
    "    eval_episodes: int = 1\n",
    "    render_mode: str = None  # use \"human\" to watch interactively\n",
    "\n",
    "@dataclass\n",
    "class EAConfig:\n",
    "    mu: int = 30\n",
    "    lam: int = 60\n",
    "    generations: int = 60\n",
    "    tourney_k: int = 3\n",
    "    swap_p: float = 0.5\n",
    "    pmut: float = 0.25\n",
    "    sigma: float = 0.12\n",
    "    theta_clip: Tuple[float,float] = (-1.5, 1.5)\n",
    "    seed: int = 123\n",
    "\n",
    "def save_micro_state(A_last: np.ndarray, M_last: np.ndarray, cem_cfg: CEMConfig, path: str):\n",
    "    \"\"\"\n",
    "    Save final micro-state as .npz (portable, precise).\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    np.savez(path, A_last=A_last, M_last=M_last, N=cem_cfg.N, T=cem_cfg.T,\n",
    "             dt=cem_cfg.dt, alpha_m=cem_cfg.alpha_m)\n",
    "\n",
    "# ---------- Persistent-state micro-simulation ----------\n",
    "def cem_force_step_persistent(model, obs: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Use ONE persistent CEM. Carry internal state across env steps by copying\n",
    "    last micro-state into t=0, then inject current observation and run T steps.\n",
    "    \"\"\"\n",
    "    # carry state forward\n",
    "\n",
    "\n",
    "    model.A[0] = model.A[-1]\n",
    "\n",
    "    # unpack CartPole obs -> (x, dx, theta, dtheta)\n",
    "    x, dx, th, dth = map(float, obs)\n",
    "\n",
    "    # run T micro-steps with current inputs seeded at t=0\n",
    "    force_vec = model.simulate(x, dx, th, dth)  # shape: (T+1, 1)\n",
    "    return float(force_vec[-1, 0])              # last micro-step output\n",
    "\n",
    "\n",
    "\n",
    "def run_episode_return_state(theta: Dict[str, float],\n",
    "                             cem_cfg: CEMConfig,\n",
    "                             env_id: str,\n",
    "                             max_steps: int,\n",
    "                             seed: int) -> Tuple[float, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Persistent-state run. Returns (return_sum, A_last, M_last) from the final env step.\n",
    "    \"\"\"\n",
    "    import gymnasium as gym\n",
    "    env = gym.make(env_id, render_mode=None, max_episode_steps=max_steps)\n",
    "    try:\n",
    "        obs, _ = env.reset(seed=seed)\n",
    "        model = CEM1Layer(N=cem_cfg.N, T=cem_cfg.T, dt=cem_cfg.dt, alpha_m=cem_cfg.alpha_m)\n",
    "        # body params only\n",
    "        model.theta.update({k: theta[k] for k in model.theta.keys()})\n",
    "\n",
    "        total = 0.0\n",
    "        for _ in range(max_steps):\n",
    "            # carry persistent micro-state\n",
    "            model.A[0] = model.A[-1]\n",
    "\n",
    "\n",
    "            x, dx, th, dth = map(float, obs)   # plug in normalization if you use it\n",
    "            force_series = model.simulate(x, dx, th, dth)  # (T+1, 1)\n",
    "            force = float(force_series[-1, 0])  # or your smoothed/out_head version\n",
    "            action = 0 if force < 0.0 else 1\n",
    "\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            total += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        A_last = model.A[-1].copy()\n",
    "\n",
    "        return float(total), A_last, A_last\n",
    "    finally:\n",
    "        env.close()\n",
    "\n",
    "def evaluate_theta_with_state(theta: Dict[str, float],\n",
    "                              cem_cfg: CEMConfig,\n",
    "                              eval_cfg: EvalConfig,\n",
    "                              base_seed: int) -> Tuple[float, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Averages fitness over eval_episodes. Returns:\n",
    "      (mean_fitness, A_last, M_last)\n",
    "    where A_last/M_last are from the *last episode evaluated*.\n",
    "    \"\"\"\n",
    "    returns = []\n",
    "    A_last = None\n",
    "    M_last = None\n",
    "    for i in range(eval_cfg.eval_episodes):\n",
    "        ret, A_last, M_last = run_episode_return_state(\n",
    "            theta, cem_cfg, eval_cfg.env_id, eval_cfg.max_steps, base_seed + i*9973\n",
    "        )\n",
    "        returns.append(ret)\n",
    "    return float(np.mean(returns)), A_last, M_last\n",
    "\n",
    "# top-level fn for ProcessPoolExecutor\n",
    "def _eval_one(args):\n",
    "    theta, cem_cfg, eval_cfg, base_seed = args\n",
    "    fit, A_last, M_last = evaluate_theta_with_state(theta, cem_cfg, eval_cfg, base_seed)\n",
    "    # return EVERYTHING we need: params, sigmas, fitness, and the final micro-state\n",
    "    return (theta,  float(fit), A_last, M_last)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- IO helpers ----------\n",
    "def save_theta(theta: Theta, path: str):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(theta, f, indent=2)\n",
    "\n",
    "def load_theta(path: str) -> Theta:\n",
    "    with open(path, \"r\") as f:\n",
    "        return {k: float(v) for k, v in json.load(f).items()}\n",
    "\n",
    "def save_checkpoint(gen: int, pop_fit: List[Tuple[Theta, float]], out_dir=\"checkpoints\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    # save top-1\n",
    "    best_idx = int(np.argmax([f for _, f in pop_fit]))\n",
    "    best_theta, best_fit = pop_fit[best_idx]\n",
    "    save_theta(best_theta, os.path.join(out_dir, f\"best_gen{gen:04d}.json\"))\n",
    "    # also save small leaderboard\n",
    "    board = [{\"rank\": i+1, \"fitness\": float(pop_fit[i][1]), \"theta\": pop_fit[i][0]}\n",
    "             for i in range(min(5, len(pop_fit)))]\n",
    "    with open(os.path.join(out_dir, f\"top5_gen{gen:04d}.json\"), \"w\") as f:\n",
    "        json.dump(board, f, indent=2)\n",
    "\n",
    "# ---------- (μ + λ) EA with PARALLEL evaluation ----------\n",
    "\n",
    "def _eval_many_serial(args_list):\n",
    "    \"\"\"Strictly serial evaluation; avoids any multiprocessing.\"\"\"\n",
    "    return [_eval_one(args) for args in args_list]\n",
    "\n",
    "def evolve_cartpole_with_cem(cem_cfg=CEMConfig(), eval_cfg=EvalConfig(), ea_cfg=EAConfig(),\n",
    "                             out_dir=\"runs/cem_ea\"):\n",
    "    rng = np.random.default_rng(ea_cfg.seed)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # init μ parents\n",
    "    population: List[Theta] = [random_theta(rng) for _ in range(ea_cfg.mu)]\n",
    "    base_seed = ea_cfg.seed * 11\n",
    "\n",
    "    args = [(clone_theta(th), cem_cfg, eval_cfg, base_seed + i*1000)\n",
    "        for i, th in enumerate(population)]\n",
    "    pop_fit = _eval_many_serial(args)\n",
    "\n",
    "    history = []\n",
    "    best_over_time: List[Tuple[Theta, float]] = []\n",
    "\n",
    "    for gen in range(ea_cfg.generations):\n",
    "        fits = [f for (_,  f, _, _) in pop_fit]\n",
    "        best_idx = int(np.argmax(fits))\n",
    "        best_theta, best_fit, best_A_last, best_M_last = pop_fit[best_idx]\n",
    "        save_theta(best_theta, os.path.join(out_dir, \"best_theta.json\"))\n",
    "        save_micro_state(best_A_last, best_M_last,cem_cfg, os.path.join(out_dir, \"best_micro_state.npz\"))\n",
    "        history.append({\n",
    "            \"generation\": gen,\n",
    "            \"mean_fitness\": float(np.mean(fits)),\n",
    "            \"std_fitness\": float(np.std(fits)),\n",
    "            \"max_fitness\": float(np.max(fits)),\n",
    "            \"min_fitness\": float(np.min(fits)),\n",
    "        })\n",
    "        best_over_time.append((clone_theta(best_theta), float(best_fit)))\n",
    "        print(f\"[Gen {gen:03d}] mean={np.mean(fits):.2f} best={best_fit:.2f}\")\n",
    "\n",
    "\n",
    "        if np.mean(fits).__int__() == eval_cfg.max_steps:\n",
    "            print(\"Stopping Early\")\n",
    "            break\n",
    "\n",
    "        # save rolling best + small leaderboard\n",
    "        #save_checkpoint(gen, pop_fit, out_dir=os.path.join(out_dir, \"checkpoints\"))\n",
    "\n",
    "        # λ offspring\n",
    "        offspring: List[Theta] = []\n",
    "        for _ in range(ea_cfg.lam):\n",
    "            p1 = tournament_select(pop_fit, rng, k=ea_cfg.tourney_k)\n",
    "            p2 = tournament_select(pop_fit, rng, k=ea_cfg.tourney_k)\n",
    "            child = uniform_crossover(p1, p2, rng, swap_p=ea_cfg.swap_p)\n",
    "            child = mutate(child, rng, pmut=ea_cfg.pmut, sigma=ea_cfg.sigma, clip=ea_cfg.theta_clip)\n",
    "            offspring.append(child)\n",
    "\n",
    "        # evaluate offspring in parallel with fresh seeds (reduce overfit to single RNG stream)\n",
    "        gen_seed_base = base_seed + (gen+1)*100_000\n",
    "        args = [(clone_theta(ch), cem_cfg, eval_cfg, gen_seed_base + i*1000)\n",
    "        for i, ch in enumerate(offspring)]\n",
    "        off_fit = _eval_many_serial(args)\n",
    "\n",
    "\n",
    "        # μ + λ truncation\n",
    "        pool = pop_fit + off_fit\n",
    "        pool.sort(key=lambda tf: tf[1], reverse=True)\n",
    "        pop_fit = pool[:ea_cfg.mu]\n",
    "\n",
    "    # final best & logs\n",
    "    fits = [f for (_,  f, _, _) in pop_fit]\n",
    "    best_idx = int(np.argmax(fits))\n",
    "    best_theta, best_fit, best_A_last, best_M_last = pop_fit[best_idx]\n",
    "    \"\"\"save_theta(best_theta, os.path.join(out_dir, \"best_theta.json\"))\n",
    "    save_micro_state(best_A_last, best_M_last,cem_cfg, os.path.join(out_dir, \"best_micro_state.npz\"))\"\"\"\n",
    "\n",
    "    # save best +\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open(os.path.join(out_dir, \"history.json\"), \"w\") as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "\n",
    "    return {\n",
    "        \"best_theta\": clone_theta(best_theta),\n",
    "        \"best_fitness\": float(best_fit),\n",
    "        \"history\": history,\n",
    "        \"best_over_time\": best_over_time,\n",
    "        \"run_dir\": out_dir,\n",
    "    }\n",
    "\n",
    "# ---------- Video rendering ----------\n",
    "def render_video_with_theta(theta: Dict[str, float], cem_cfg: CEMConfig,\n",
    "                            env_id=\"CartPole-v1\", max_steps=500,\n",
    "                            video_dir=\"videos\", name_prefix=\"cem_cartpole\",\n",
    "                            microstate_path: str | None = None,\n",
    "                            seed: int = 2025):\n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "    env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "    env = RecordVideo(env, video_folder=video_dir, name_prefix=name_prefix,\n",
    "                      episode_trigger=lambda i: True)\n",
    "    try:\n",
    "        obs, _ = env.reset(seed=seed)\n",
    "\n",
    "        model = CEM1Layer(N=cem_cfg.N, T=cem_cfg.T, dt=cem_cfg.dt, alpha_m=cem_cfg.alpha_m)\n",
    "        # body params only\n",
    "        body_keys = list(model.theta.keys())\n",
    "        model.theta.update({k: theta[k] for k in body_keys})\n",
    "\n",
    "        # --- Inject saved micro-state (if provided) ---\n",
    "        if microstate_path is not None and os.path.exists(microstate_path):\n",
    "            print(\"Loading microstate from {}\".format(microstate_path))\n",
    "            data = np.load(microstate_path)\n",
    "            A_last = data[\"A_last\"]\n",
    "            model.A[-1] = A_last\n",
    "            # initialize persistent internal state to saved last micro-step\n",
    "\n",
    "            \"\"\"model.A[-1] = A_last\n",
    "            model.M[-1] = M_last\"\"\"\n",
    "        else:\n",
    "            # otherwise start from model's default A[0], M[0]\n",
    "            pass\n",
    "\n",
    "        total = 0.0\n",
    "        for _ in range(max_steps):\n",
    "            # persistent carryover for each env step\n",
    "            model.A[0] = model.A[-1]\n",
    "\n",
    "\n",
    "            x, dx, th, dth = obs  # or normalized if you use norm_obs\n",
    "            force_series = model.simulate(float(x), float(dx), float(th), float(dth))\n",
    "            force = float(force_series[-1, 0])\n",
    "\n",
    "            action = 0 if force < 0.0 else 1\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            total += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "\n",
    "        print(f\"Episode return (video): {total:.1f}\")\n",
    "    finally:\n",
    "        env.close()\n",
    "    print(f\"Video saved to: {os.path.abspath(video_dir)}  (look for {name_prefix}-episode-*.mp4)\")\n",
    "\n",
    "\n",
    "# --- helper: draw A overlay (top-right) ---\n",
    "def _draw_A_overlay(frame: np.ndarray, A: np.ndarray,\n",
    "                    panel_w: int = 260, panel_h: int = 100,\n",
    "                    margin: int = 12, bar_pad: int = 6) -> np.ndarray:\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "    # defensive: ensure HxWx3 uint8\n",
    "    frame = np.asarray(frame)\n",
    "    if frame.dtype != np.uint8:\n",
    "        frame = np.clip(frame, 0, 255).astype(np.uint8)\n",
    "    if frame.ndim == 2:\n",
    "        frame = np.repeat(frame[..., None], 3, axis=2)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    im = Image.fromarray(frame).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    # panel rect (top-right)\n",
    "    x1 = max(0, w - panel_w - margin)\n",
    "    y1 = max(0, margin)\n",
    "    x2 = min(w - 1, w - margin)\n",
    "    y2 = min(h - 1, margin + panel_h)\n",
    "\n",
    "    # ensure valid panel rect\n",
    "    if x2 <= x1 + 2 or y2 <= y1 + 2:\n",
    "        return np.array(im.convert(\"RGB\"), dtype=np.uint8)\n",
    "\n",
    "    # bg\n",
    "    try:\n",
    "        font = ImageFont.load_default()\n",
    "    except Exception:\n",
    "        font = None\n",
    "    draw.rounded_rectangle([x1, y1, x2, y2], radius=10,\n",
    "                           fill=(0, 0, 0, 160), outline=(255, 255, 255, 180), width=1)\n",
    "\n",
    "    # stats\n",
    "    if A.size == 0:\n",
    "        text = \"A  (empty)\"\n",
    "        draw.text((x1 + 10, y1 + 8), text, fill=(255, 255, 255, 230), font=font)\n",
    "        return np.array(im.convert(\"RGB\"), dtype=np.uint8)\n",
    "\n",
    "    A_min = float(np.min(A))\n",
    "    A_mean = float(np.mean(A))\n",
    "    A_max = float(np.max(A))\n",
    "    draw.text((x1 + 10, y1 + 8),\n",
    "              f\"A  min {A_min:+.2f}  mean {A_mean:+.2f}  max {A_max:+.2f}\",\n",
    "              fill=(255, 255, 255, 230), font=font)\n",
    "\n",
    "    # bar area\n",
    "    bars_x1 = x1 + 10\n",
    "    bars_y1 = y1 + 28\n",
    "    bars_x2 = x2 - 10\n",
    "    bars_y2 = y2 - 10\n",
    "    bars_w = max(1, bars_x2 - bars_x1)\n",
    "    bars_h = max(2, bars_y2 - bars_y1)  # need >=2 for zero line + 1px bars\n",
    "\n",
    "    # zero line\n",
    "    zero_y = bars_y1 + bars_h // 2\n",
    "    zero_y = int(np.clip(zero_y, bars_y1, bars_y2))  # within area\n",
    "    draw.line([(bars_x1, zero_y), (bars_x2, zero_y)], fill=(200, 200, 200, 180), width=1)\n",
    "\n",
    "    # scale A per-frame to [-1, 1] (robust)\n",
    "    denom = float(max(1e-6, np.max(np.abs(A))))\n",
    "    A_unit = (A / denom).astype(float)\n",
    "\n",
    "    n = int(len(A_unit))\n",
    "    if n > 0:\n",
    "        # bar width + gap\n",
    "        bw = max(1, bars_w // n)\n",
    "        gap = max(0, int(0.15 * bw))\n",
    "        bw_eff = max(1, bw - gap)\n",
    "\n",
    "        for i, val in enumerate(A_unit):\n",
    "            bx1 = bars_x1 + i * bw\n",
    "            bx2 = min(bars_x2, bx1 + bw_eff)\n",
    "            if bx2 <= bx1:\n",
    "                continue  # nothing to draw\n",
    "\n",
    "            height = int((bars_h / 2) * min(1.0, abs(val)))\n",
    "            if height < 1:\n",
    "                height = 1  # ensure at least 1px visible\n",
    "\n",
    "            if val >= 0:\n",
    "                y_top = int(np.clip(zero_y - height, bars_y1, bars_y2))\n",
    "                y_bot = int(np.clip(zero_y - 1, bars_y1, bars_y2))\n",
    "                color = (120, 200, 255, 220)\n",
    "            else:\n",
    "                y_top = int(np.clip(zero_y + 1, bars_y1, bars_y2))\n",
    "                y_bot = int(np.clip(zero_y + height, bars_y1, bars_y2))\n",
    "                color = (255, 160, 120, 220)\n",
    "\n",
    "            # enforce y_top <= y_bot to satisfy PIL\n",
    "            if y_bot < y_top:\n",
    "                y_top, y_bot = y_bot, y_top\n",
    "            if y_bot == y_top:  # still a line -> extend 1px\n",
    "                y_bot = min(bars_y2, y_bot + 1)\n",
    "\n",
    "            draw.rectangle([bx1, y_top, bx2, y_bot], fill=color)\n",
    "\n",
    "    return np.array(im.convert(\"RGB\"), dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "def _bwr_rgb_from_unit(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    x in [-1, 1] -> RGB (uint8), blue-white-red\n",
    "    \"\"\"\n",
    "    x = np.clip(x, -1.0, 1.0)\n",
    "    R = np.where(x >= 0, 255.0, (1.0 + x) * 255.0)         # x<0: fade red down\n",
    "    G = np.where(x >= 0, (1.0 - x) * 255.0, (1.0 + x) * 255.0)\n",
    "    B = np.where(x >= 0, (1.0 - x) * 255.0, 255.0)         # x<0: strong blue\n",
    "    rgb = np.stack([R, G, B], axis=-1)\n",
    "    return np.clip(rgb, 0, 255).astype(np.uint8)\n",
    "\n",
    "def _unrolled_A_to_frame(A_roll: np.ndarray, scale: int = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    A_roll: (T+1, N) float -> RGB image as ndarray (H, W, 3).\n",
    "    Normalizes by max abs within this micro-rollout for visibility.\n",
    "    Upscales with nearest-neighbor by `scale`.\n",
    "    \"\"\"\n",
    "    A = np.asarray(A_roll, dtype=float)\n",
    "    # normalize per micro-rollout\n",
    "    denom = float(np.max(np.abs(A))) if np.max(np.abs(A)) > 1e-12 else 1.0\n",
    "    An = A / denom\n",
    "    rgb = _bwr_rgb_from_unit(An)  # (T+1, N, 3)\n",
    "    if scale != 1:\n",
    "        h, w = rgb.shape[:2]\n",
    "        img = Image.fromarray(rgb, mode=\"RGB\").resize((w*scale, h*scale), resample=Image.NEAREST)\n",
    "        rgb = np.array(img, dtype=np.uint8)\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def render_video_with_theta_and_A_overlay(\n",
    "    theta: dict,\n",
    "    cem_cfg,\n",
    "    env_id: str = \"CartPole-v1\",\n",
    "    max_steps: int = 500,\n",
    "    out_path: str = \"videos/cem_cartpole_best_with_A.mp4\",\n",
    "    microstate_path: str | None = None,\n",
    "    seed: int | None = None,\n",
    "    # these must match training if you used them:\n",
    "    use_norm: bool = False,\n",
    "    smooth_k: int = 1,\n",
    "    out_head: dict | None = None,\n",
    "    fps: int = 30,\n",
    "    unrolled_out_path: str | None = \"videos/cem_cartpole_A_unrolled.mp4\",\n",
    "    unrolled_scale: int = 2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Records a video with the CEM-controlled episode and overlays the current A state\n",
    "    at the top-right in every frame.\n",
    "\n",
    "    - If microstate_path is provided (npz with A_last, M_last, and seed), we start from that state and seed.\n",
    "    - use_norm / smooth_k / out_head must mirror training for consistent behavior.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "    if unrolled_out_path is not None:\n",
    "        os.makedirs(os.path.dirname(unrolled_out_path) or \".\", exist_ok=True)\n",
    "\n",
    "    # Load micro-state (and seed) if provided\n",
    "    A0 = M0 = None\n",
    "    if microstate_path and os.path.exists(microstate_path):\n",
    "        data = np.load(microstate_path)\n",
    "        A0 = data[\"A_last\"]\n",
    "        M0 = data[\"M_last\"]\n",
    "        if seed is None and \"seed\" in data:\n",
    "            seed = int(data[\"seed\"])\n",
    "\n",
    "    if seed is None:\n",
    "        seed = 2025\n",
    "\n",
    "    env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "    writer = imageio.get_writer(out_path, fps=fps, codec=\"libx264\", quality=8)\n",
    "    unrolled_writer = None\n",
    "    if unrolled_out_path:\n",
    "        unrolled_writer = imageio.get_writer(unrolled_out_path, fps=fps, codec=\"libx264\", quality=8)\n",
    "    total = 0.0\n",
    "    try:\n",
    "        obs, _ = env.reset(seed=seed)\n",
    "\n",
    "        # build model (persistent across env steps)\n",
    "        model = CEM1Layer(N=cem_cfg.N, T=cem_cfg.T, dt=cem_cfg.dt, alpha_m=cem_cfg.alpha_m)\n",
    "        # body params only\n",
    "        model.theta.update({k: theta[k] for k in model.theta.keys()})\n",
    "\n",
    "        # inject saved micro-state before first step\n",
    "        if A0 is not None:\n",
    "            model.A[0] = A0\n",
    "\n",
    "\n",
    "        first_step = True\n",
    "        for _ in range(max_steps):\n",
    "            # carry persistent micro-state (skip overwrite on the very first frame)\n",
    "            if not first_step:\n",
    "                model.A[0] = model.A[-1]\n",
    "\n",
    "            first_step = False\n",
    "\n",
    "            # (optional) normalize obs exactly as during training\n",
    "            x, dx, th, dth = obs\n",
    "\n",
    "\n",
    "            force_series = model.simulate(float(x), float(dx), float(th), float(dth))  # (T+1,1)\n",
    "            A_unrolled = model.A.copy()          # shape: (T+1, N)\n",
    "            unrolled_frame = _unrolled_A_to_frame(A_unrolled, scale=unrolled_scale)\n",
    "            if unrolled_writer is not None:\n",
    "                unrolled_writer.append_data(unrolled_frame)\n",
    "\n",
    "            # readout (match training)\n",
    "            if smooth_k and smooth_k > 1:\n",
    "                k = min(smooth_k, force_series.shape[0])\n",
    "                base_force = float(force_series[-k:, 0].mean())\n",
    "            else:\n",
    "                base_force = float(force_series[-1, 0])\n",
    "\n",
    "            if out_head is not None:\n",
    "                    force = out_head.get(\"out_gain\", 1.0) * base_force + out_head.get(\"out_bias\", 0.0)\n",
    "            else:\n",
    "                force = base_force\n",
    "\n",
    "            action = 0 if force < 0.0 else 1\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            total += reward\n",
    "\n",
    "            # grab a frame and overlay A (panel rendered at top-right)\n",
    "            frame = env.render()  # rgb_array\n",
    "            # use *current* A baseline for overlay (already updated this step)\n",
    "            A_current = model.A[-1]\n",
    "            frame = _draw_A_overlay(frame, A_current)\n",
    "\n",
    "            writer.append_data(frame)\n",
    "\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "    finally:\n",
    "        writer.close()\n",
    "        if unrolled_writer is not None:\n",
    "            unrolled_writer.close()\n",
    "        env.close()\n",
    "\n",
    "    print(f\"Episode return (video): {total:.1f}\")\n",
    "    print(f\"Saved video with A overlay to: {os.path.abspath(out_path)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d68a76631aa8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:56:07.478335Z",
     "start_time": "2025-09-29T16:53:59.391827Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Example usage ----------\n",
    "for i in range(10):\n",
    "    c1 =CEMConfig(N=30, T=150, dt=0.3, alpha_m=0.2)\n",
    "    # 1) Train (parallel)\n",
    "    result = evolve_cartpole_with_cem(\n",
    "        cem_cfg=c1,\n",
    "        eval_cfg=EvalConfig(env_id=\"CartPole-v1\", eval_episodes=1, max_steps=300),\n",
    "        ea_cfg=EAConfig(mu=50, lam=100, generations=4, pmut=0.15,sigma=0.1,tourney_k=10, seed=i+25),\n",
    "        out_dir=\"runs/cem_ea_parallel\",\n",
    "    )\n",
    "    print(\"Best fitness:\", result[\"best_fitness\"])\n",
    "    print(\"Best theta saved at:\", os.path.join(result[\"run_dir\"], \"best_theta.json\"))\n",
    "    best_theta = load_theta(os.path.join(result[\"run_dir\"], \"best_theta.json\"))\n",
    "    micro_path = os.path.join(result[\"run_dir\"], \"best_micro_state.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9dae483d809b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T16:56:13.000351Z",
     "start_time": "2025-09-29T16:56:07.487932Z"
    }
   },
   "outputs": [],
   "source": [
    " render_video_with_theta(best_theta, cem_cfg=c1, env_id=\"CartPole-v1\",\n",
    "                        max_steps=300, video_dir=\"videos\",\n",
    "                        name_prefix=\"cem_cartpole_best\",\n",
    "                        microstate_path=micro_path, seed=2025)\n",
    "\n",
    "    # 2) Visualize best (make a video)\n",
    "\n",
    "render_video_with_theta_and_A_overlay(best_theta, cem_cfg=c1, env_id=\"CartPole-v1\",\n",
    "                        max_steps=500, out_path=\"videos/cem_cartpole_best_with_A.mp4\",\n",
    "\n",
    "                        microstate_path=micro_path, seed=2025)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slackenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
